"""
Parse JRA race result HTML into v4 schema dicts.
"""

from __future__ import annotations

import logging
import re
from pathlib import Path
from typing import Any, Dict, List, Tuple, Union

import pandas as pd
from bs4 import BeautifulSoup

logger = logging.getLogger(__name__)

JP_DATE_PATTERN = r"(\d{4})\u5e74\s*(\d{1,2})\u6708\s*(\d{1,2})\u65e5"
JP_TURF = "\u829d"
JP_DIRT = "\u30c0\u30fc\u30c8"


def _read_html_text(path: Path) -> str:
    try:
        return path.read_text(encoding="utf-8")
    except UnicodeDecodeError:
        return path.read_text(encoding="shift_jis", errors="ignore")


def _infer_race_id(html_path: Path) -> str:
    m = re.search(r"(\d{12})", html_path.stem)
    return m.group(1) if m else html_path.stem


def _safe_int(val: Any) -> int | None:
    try:
        if pd.isna(val):
            return None
        return int(str(val).strip().replace(",", ""))
    except Exception:
        return None


def _safe_float(val: Any) -> float | None:
    try:
        if pd.isna(val):
            return None
        return float(str(val).strip().replace(",", ""))
    except Exception:
        return None


def _parse_time_to_sec(time_str: str | None) -> float | None:
    if not isinstance(time_str, str):
        return None
    s = time_str.strip()
    if not s:
        return None
    m = re.match(r"(?:(\d+):)?(\d+(?:\.\d+)?)$", s)
    if not m:
        return None
    minutes = m.group(1)
    seconds = float(m.group(2))
    return (int(minutes) * 60 + seconds) if minutes is not None else seconds


def _parse_margin_to_sec(margin: str | None) -> float | None:
    if not isinstance(margin, str):
        return None
    txt = margin.strip()
    if not txt or txt in ['-', '']:
        return None

    # numeric-like value
    try:
        return float(txt)
    except ValueError:
        pass

    base = 0.2  # rough seconds per 1??
    mapping = {
        "ãƒãƒŠ": 0.05,  # ??
        "é¼»": 0.05,  # ?
        "ã‚¢ã‚¿ãƒE: 0.15,  # ???
        "ã‚¯ãƒE: 0.1,  # ??
        "åŠé¦¬èº«": base * 0.5,
        "1/4": base * 0.25,
        "1/2": base * 0.5,
        "3/4": base * 0.75,
        "å¤§å·®": None,  # ??
    }
    for k, v in mapping.items():
        if k in txt:
            return v

    m_len = re.match(r"([0-9]+(?:\.[0-9]+)?)\s*é¦¬èº«", txt)
    if m_len:
        return float(m_len.group(1)) * base
    return None


def _slugify(text: str) -> str:
    return re.sub(r"[^A-Za-z0-9]+", "_", text.strip()).strip("_")


def _make_id(prefix: str, name: str | None, fallback: str) -> str:
    if name:
        slug = _slugify(name)
        if slug:
            return f"{prefix}_{slug}"
    return fallback


def _parse_race_overview(soup: BeautifulSoup, race_id: str) -> Dict[str, Any]:
    info: Dict[str, Any] = {
        "race_id": race_id,
        "date": None,
        "race_name": None,
        "distance": None,
        "surface": None,
        "weather": None,
        "going": None,
        "class": None,
        "age_cond": None,
        "sex_cond": None,
        "race_no": None,
        "num_runners": None,
    }

    header_text = soup.get_text("\n", strip=True)

    m_date = re.search(JP_DATE_PATTERN, header_text)
    if m_date:
        y, mn, d = m_date.groups()
        info["date"] = f"{int(y):04d}-{int(mn):02d}-{int(d):02d}"
    else:
        m_fallback = re.match(r"(\d{4})(\d{2})(\d{2})", race_id)
        if m_fallback:
            y, mn, d = m_fallback.groups()
            info["date"] = f"{y}-{mn}-{d}"

    h2 = soup.find("h2")
    if h2 and h2.text.strip():
        info["race_name"] = h2.text.strip()

    m_r = re.search(r"(\d+)\s*R", header_text)
    if m_r:
        info["race_no"] = int(m_r.group(1))

    m_dist = re.search(r"([\u829d\u30c0\u30fc\u30c8])\s*([\d,]+)m", header_text)
    if m_dist:
        surf_jp, dist_str = m_dist.groups()
        info["distance"] = int(dist_str.replace(",", ""))
        info["surface"] = "turf" if surf_jp == JP_TURF else "dirt"

    m_weather = re.search(r"\u5929\u5019[:\uFF1A]\s*([^\s\u3000]+)", header_text)
    if m_weather:
        info["weather"] = m_weather.group(1)
    m_going = re.search(r"(?:\u829d|\u30c0\u30fc\u30c8)[:\uFF1A]\s*([^\s\u3000]+)", header_text)
    if m_going:
        info["going"] = m_going.group(1)

    # class (rough)
    cls_candidates = [
        ("\u30b0\u30ec\u30fc\u30c91", "G1"),
        ("\u30b0\u30ec\u30fc\u30c92", "G2"),
        ("\u30b0\u30ec\u30fc\u30c93", "G3"),
        ("G1", "G1"),
        ("G2", "G2"),
        ("G3", "G3"),
        ("\u30aa\u30fc\u30d7\u30f3", "OPEN"),
        ("\u30aa\u30fc\u30d7\u30f3\u7279\u5225", "OPEN"),
        ("\u7279\u5225", "OP"),
        ("\u65b0\u99ac", "NEW"),
        ("\u672a\u52dd\u5229", "MAIDEN"),
    ]
    for pat, label in cls_candidates:
        if pat in header_text:
            info["class"] = label
            break
    if info["class"] is None:
        m_cls = re.search(r"(\d)\u52dd\u30af\u30e9\u30b9", header_text)
        if m_cls:
            info["class"] = f"{m_cls.group(1)}-WIN"

    # age condition
    m_age = re.search(r"(\d)[\u6b73\u624d]\u4ee5\u4e0a", header_text)
    if m_age:
        info["age_cond"] = f"{m_age.group(1)}YO+"
    else:
        m_age2 = re.search(r"(\d)[\u6b73\u624d]", header_text)
        if m_age2:
            info["age_cond"] = f"{m_age2.group(1)}YO"

    # sex condition
    if "\u54c1\u99ac" in header_text or "\u54c1" in header_text:
        info["sex_cond"] = "FEMALE"
    if "\u725b\u99ac" in header_text or "\u725b" in header_text:
        info["sex_cond"] = "MALE"
    if "\u725b\u30fb\u54c1" in header_text or "\u725b\u54c1" in header_text or "\u725b\u30fb\u54c1\u99ac" in header_text:
        info["sex_cond"] = "MIX"

    return info


def _find_results_table(soup: BeautifulSoup):
    th_place = soup.find("th", class_="place")
    if th_place:
        return th_place.find_parent("table")
    for table in soup.find_all("table"):
        if table.find(string=re.compile("\u7740\u9806")):
            return table
    tables = soup.find_all("table")
    return tables[0] if tables else None


def _parse_results_table(soup: BeautifulSoup) -> pd.DataFrame:
    table = _find_results_table(soup)
    if table is None:
        logger.warning("Result table not found")
        return pd.DataFrame()
    try:
        df = pd.read_html(str(table))[0]
    except ValueError:
        logger.warning("pandas.read_html failed on result table")
        return pd.DataFrame()

    def _norm_col(col: Any) -> str:
        s = str(col)
        for ch in [" ", "ã€€", "Â ", "E¿"]:
            s = s.replace(ch, "")
        return s

    col_map: Dict[Any, str] = {}
    for col in df.columns:
        norm = _norm_col(col)
        if "ç€é E in norm or norm == "ç€":
            col_map[col] = "finish_rank"
        elif norm in {"æž¡", "æž¡ç•ª"}:
            col_map[col] = "bracket_no"
        elif "é¦¬ç•ª" in norm:
            col_map[col] = "horse_no"
        elif "é¦¬åE in norm:
            col_map[col] = "horse_name"
        elif "æ€§é½¢" in norm:
            col_map[col] = "sex_age"
        elif "æ–¤é‡E in norm:
            col_map[col] = "weight"
        elif "é¨Žæ‰‹" in norm:
            col_map[col] = "jockey_name"
        elif "ã‚¿ã‚¤ãƒ " in norm or "æ‰€è¦E in norm or "èµ°ç ´" in norm:
            col_map[col] = "time_str"
        elif "ç€å·®" in norm:
            col_map[col] = "margin_str"
        elif "é€šéŽ" in norm or "ã‚³ãƒ¼ãƒE in norm:
            col_map[col] = "corner_pass_order"
        elif "ä¸Šã‚Š" in norm or "ä¸ŠãŒã‚E in norm or "æŽ¨å®šä¸ŠãŒã‚E in norm:
            col_map[col] = "last_3f"
        elif "å˜å‹" in norm:
            col_map[col] = "odds"
        elif "äººæ°E in norm:
            col_map[col] = "popularity"
        elif "é¦¬ä½“é‡" in norm:
            col_map[col] = "body_weight_raw"
        elif "èª¿æ•™å¸«" in norm:
            col_map[col] = "trainer_name"
    if col_map:
        df = df.rename(columns=col_map)

    def _clean_corner(val: Any) -> str | None:
        if pd.isna(val):
            return None
        s = str(val).strip()
        if not s or s.lower() == "nan":
            return None
        s = re.sub(r"[^\d/\-,]", "", s)
        s = s.replace("?", "/").replace("?", "-").replace("?", "-")
        s = s.replace("/", "-").replace(",", "-")
        s = re.sub(r"-+", "-", s)
        return s or None

    if "corner_pass_order" in df.columns:
        df["corner_pass_order"] = df["corner_pass_order"].apply(_clean_corner)

    if "sex_age" in df.columns:
        se = df["sex_age"].astype(str).str.extract(r"([ç‰›ç‰ã‚»ç™ºé¨™])\s*(\d+)")
        df["sex"] = se[0]
        df["age"] = pd.to_numeric(se[1], errors="coerce").astype("Int64")

    if "body_weight_raw" in df.columns:
        w = df["body_weight_raw"].astype(str).str.extract(r"(\d+)\s*\(([+\-âˆ’]?\d+)\)")
        df["body_weight"] = pd.to_numeric(w[0], errors="coerce").astype("Int64")
        df["body_weight_diff"] = pd.to_numeric(w[1], errors="coerce").astype("Int64")

    return df


def parse_jra_race(html_path: Union[str, Path]) -> Tuple[Dict[str, Any], List[Dict[str, Any]], Dict[str, Dict[str, Any]], Dict[str, Dict[str, Any]], Dict[str, Dict[str, Any]]]:
    path = Path(html_path)
    if not path.exists():
        raise FileNotFoundError(f"HTML not found: {path}")
    race_id = _infer_race_id(path)
    html = _read_html_text(path)
    soup = BeautifulSoup(html, "html.parser")

    race_info = _parse_race_overview(soup, race_id)
    df = _parse_results_table(soup)

    distance = race_info.get("distance") or 0
    surface = race_info.get("surface") or "unknown"
    course_id = f"UNK_{surface}_{distance}"

    race_dict: Dict[str, Any] = {
        "race_id": race_id,
        "date": race_info.get("date"),
        "course_id": course_id,
        "race_no": race_info.get("race_no") or 0,
        "race_name": race_info.get("race_name"),
        "distance": distance,
        "surface": surface,
        "weather": race_info.get("weather"),
        "going": race_info.get("going"),
        "class": race_info.get("class"),
        "age_cond": race_info.get("age_cond"),
        "sex_cond": race_info.get("sex_cond"),
        "num_runners": len(df) if not df.empty else None,
        "win_time_sec": None,
        "race_type": "FLAT",
        "venue_id": None,
    }

    results_list: List[Dict[str, Any]] = []
    horses_dict: Dict[str, Dict[str, Any]] = {}
    jockeys_dict: Dict[str, Dict[str, Any]] = {}
    trainers_dict: Dict[str, Dict[str, Any]] = {}
    unknown_counters = {"horse": 0, "jockey": 0, "trainer": 0}

    for idx, row in df.iterrows():
        horse_name = str(row.get("horse_name", "")).strip() or f"UNKNOWN_HORSE_{idx:02d}"
        jockey_name = str(row.get("jockey_name", "")).strip() or f"UNKNOWN_JOCKEY_{idx:02d}"
        trainer_name = str(row.get("trainer_name", "")).strip() or f"UNKNOWN_TRAINER_{idx:02d}"

        if horse_name.startswith("UNKNOWN_HORSE"):
            unknown_counters["horse"] += 1
        if jockey_name.startswith("UNKNOWN_JOCKEY"):
            unknown_counters["jockey"] += 1
        if trainer_name.startswith("UNKNOWN_TRAINER"):
            unknown_counters["trainer"] += 1

        horse_no = _safe_int(row.get("horse_no"))
        horse_id = _make_id("HORSE", horse_name, f"{race_id}_H{idx:02d}")
        jockey_id = _make_id("JOCKEY", jockey_name, f"{race_id}_J{idx:02d}")
        trainer_id = _make_id("TRAINER", trainer_name, f"{race_id}_T{idx:02d}")

        finish_time = _parse_time_to_sec(row.get("time_str"))
        margin_sec = _parse_margin_to_sec(row.get("margin_str"))

        horses_dict[horse_id] = {"horse_name": horse_name or None, "sex": row.get("sex"), "birth_year": None}
        jockeys_dict[jockey_id] = {"jockey_name": jockey_name or None}
        trainers_dict[trainer_id] = {"trainer_name": trainer_name or None}

        result = {
            "race_id": race_id,
            "horse_id": horse_id,
            "bracket_no": _safe_int(row.get("bracket_no")),
            "horse_no": horse_no,
            "finish_rank": _safe_int(row.get("finish_rank")),
            "finish_status": "OK" if _safe_int(row.get("finish_rank")) is not None else None,
            "finish_time_sec": finish_time,
            "odds": _safe_float(row.get("odds")),
            "popularity": _safe_int(row.get("popularity")),
            "weight": _safe_float(row.get("weight")),
            "body_weight": _safe_int(row.get("body_weight")),
            "weight_diff": _safe_int(row.get("body_weight_diff")),
            "jockey_id": jockey_id,
            "trainer_id": trainer_id,
            "corner_pass_order": row.get("corner_pass_order") if "corner_pass_order" in df.columns else None,
            "last_3f": _safe_float(row.get("last_3f")),
            "margin_sec": margin_sec,
            "prize": None,
            "prev_race_id": None,
            "prev_finish_rank": None,
            "prev_margin_sec": None,
            "prev_time_sec": None,
            "prev_last_3f": None,
            "days_since_last": None,
        }
        results_list.append(result)

    # set win_time_sec as best available (prefer rank=1 time, else min time)
    win_time = None
    for r in results_list:
        if r.get("finish_rank") == 1 and r.get("finish_time_sec") is not None:
            win_time = r["finish_time_sec"]
            break
    if win_time is None:
        times = [r.get("finish_time_sec") for r in results_list if r.get("finish_time_sec") is not None]
        if times:
            win_time = min(times)
    if win_time is not None:
        race_dict["win_time_sec"] = win_time

    # Log unknown counts to help identify encoding/parse gaps
    if any(unknown_counters.values()):
        logger.info(
            "Unknown placeholders used (race_id=%s): horse=%s, jockey=%s, trainer=%s",
            race_id,
            unknown_counters["horse"],
            unknown_counters["jockey"],
            unknown_counters["trainer"],
        )

    return race_dict, results_list, horses_dict, jockeys_dict, trainers_dict


def parse_race_html(html_path: Union[str, Path]) -> Tuple[Dict[str, Any], List[Dict[str, Any]], Dict[str, Dict[str, Any]], Dict[str, Dict[str, Any]], Dict[str, Dict[str, Any]]]:
    """Wrapper to match legacy API."""
    return parse_jra_race(html_path)


