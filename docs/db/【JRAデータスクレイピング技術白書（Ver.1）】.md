【JRAデータスクレイピング技術白書（Ver.1）】
1. JRA公式サイトのページ階層構造と遷移方式
JRA公式サイト（jra.go.jp）の競馬情報メニューは階層的に構成されており、トップページから段階的に目的のレース結果ページへ到達します。主な階層と各ページの役割・遷移方式は以下のとおりです。
トップページ（競馬メニュー） – 「開催お知らせ」「出馬表」「オッズ」「払戻金」「レース結果」等の主要コンテンツへのリンクが並んでいます。これらリンクは通常の静的URLではなく、<a>タグのonClick属性でJavaScript関数doAction()を呼び出す形式になっています
doanythings0.blogspot.com
doanythings0.blogspot.com
。各リンクはhref="#"となっており、クリック時にdoAction('/JRADB/アクセス先.html','CNAMEコード')が実行されます。例えばトップページの「レース結果」リンクはonClick="doAction('/JRADB/accessS.html','pw01sli00/AF')"という形式です
doanythings0.blogspot.com
（後述の通り、このCNAMEコードがページ遷移の鍵となります）。
開催日程（カレンダー）ページ – 年月ごとの開催スケジュールを表示するページです。トップページの競馬メニューから「開催日程」を選ぶと該当月のカレンダーが表示され、開催のある日付にリンクが設定されています。各リンクをクリックすると、その日付の開催日ページに遷移します（内部的にはJavaScriptまたは通常の<a>リンクで、対象日のパラメータを付与して遷移します）。例えば「2025年5月24日（土）」をクリックすると、その日の各開催（例：2回東京9日、2回京都9日等）が一覧されたページに移動します
jra.go.jp
。カレンダーページ自体のURLは静的に/keiba/calendar/2025XXX.html（想定）となっており、HTML構造は月間カレンダー表（各日付セル内に開催情報のリンク）というシンプルな構造です。ここでは開催日のリンクを取得するために、日付セル内の<a>タグをパースし、リンク先やテキスト（日付）を取得します。CSSセレクタ例：table.calendar a（日付セル内のリンク要素）などで該当リンクを抽出できます。
開催日ページ（開催選択） – 特定の日付に開催のある競馬場と回次を一覧するページです。その日付に複数場で開催がある場合、「○回◯◯（競馬場）◯日」といった開催名称ごとにリンクが並びます
jra.go.jp
。このページは例えば「2025年5月24日（土）」の場合、「2回東京9日」「2回京都9日」…といったリンクが表示されます。リンクの実装方式は場合によって異なり、サイトの改修によりJavaScriptのdoActionで遷移する場合と、直接<a href="/JRADB/accessS.html?CNAME=...">形式で遷移する場合があります。近年は後者の直接リンク方式も使われており、実際のHTMLでは以下のようなアンカータグになっています
ken3memo.hatenablog.com
。
<th scope="row" class="race_num">
    <a href="/JRADB/accessS.html?CNAME=pw01srl10082025052420250524/xx">2回東京9日</a>
</th>
（※コード中のpw01srl...部分は実際のCNAMEコードで、末尾/xxはチェックサムのような値） このリンクをクリックすると選択した開催のレース一覧ページへ移動します。開催日ページのHTML構造は、開催ごとのリンクを行またはリスト項目として並べたシンプルなものです。CSSセレクタ例：開催リンクは例えばa[href*="accessS.html?CNAME="]かつリンクテキストが「○回◯◯◯◯日」にマッチするものを探すことで抽出できます
doanythings0.blogspot.com
doanythings0.blogspot.com
。
レース一覧ページ（当日開催のレースリスト） – 選択した開催日における全レース（通常第1競走～最終競走）の一覧です。ページ上部には日付・開催・場名・○日目などの見出し情報が表示され、その下に各レースの情報が表形式で並んでいます。表の各行が1レースに対応し、発走時刻、レース名（本題・副題）、出走条件などが記載され、各レースの詳細ページ（出馬表・オッズ・結果など）へのリンクが設置されています
doanythings0.blogspot.com
。レース結果のリンクについては、JRAサイトではレース番号ボタンとして実装されています。例えば「1レース」「2レース」などのボタン画像があり、それぞれにレース結果ページへのリンクが設定されています
ken3memo.hatenablog.com
。HTML上は以下のように、<th class="race_num">内に各レース番号のリンクが画像付きで配置されています
ken3memo.hatenablog.com
。
<th scope="row" class="race_num">
    <a href="/JRADB/accessS.html?CNAME=pw01sde1006202301070120230121/CF">
        <img src="/JRADB/img/race_select/btn_race_num_g_1.png" alt="1レース" />
    </a>
</th>
上記例では「1レース」のボタンがあり、hrefにaccessS.html?CNAME=...という形式のURLが直接指定されています
ken3memo.hatenablog.com
。このCNAMEコード（例：pw01sde.../CF）がそのレース固有のパラメータで、クリックにより当該レースの結果ページへ遷移します。レース一覧ページのHTML構造としては、<table id="race_list">に各レースの行（<tr>）があり、上記のレース番号カラムのほか、レース名や発走時刻等のカラムが存在します
doanythings0.blogspot.com
。レース結果リンクを抽出するには、例えばCSSセレクタでtable#race_list th.race_num aを取得し、その中のhref属性からCNAMEコードを抜き取る方法が有効です。また、画像のalt属性（「○レース」）を見ればレース番号の判別も可能です
ken3memo.hatenablog.com
。※JavaScriptを使う旧形式ではonClick="doAction(...)"となっている場合もありますが、基本的にはリンクを直接取得できる構造になっています。
レース結果ページ（最終ページ） – 個別のレース結果詳細ページです。各レースごとに固有のURL/CNAMEパラメータでアクセスされ、レースの結果（着順）および関連情報が掲載されています。URL形式はhttps://www.jra.go.jp/JRADB/accessS.html?CNAME=...という形で、CNAMEにレース固有コードが含まれます（後述のとおり、このURLは通常のブラウザ操作ではdoAction経由のPOST送信で開かれますが、直接GETクエリとしても同様にアクセス可能です）。レース結果ページには、ページ見出しとして開催日・開催番号・競馬場・日次・レース番号が表示され（例：「レース結果2025年11月2日（日曜）4回東京11日 11レース」
jra.go.jp
）、続いてレース名や条件、天候・馬場状態などの概要、そして着順表（結果表）が載っています。このページのHTML構造詳細については後述しますが、table要素で着順表が構成され、馬名や騎手名はリンク付きで表示されるなど、所定のマークアップがなされています。
各ページ間の遷移は以上のように段階的であり、特にJRA公式サイトでは直接特定レースのページURLにアクセスするのではなく、一連のフォーム送信やリンククリック（JavaScript経由含む）によって遷移する設計になっています。トップページ→開催日程→開催日→レース一覧→レース結果というヒエラルキーを辿ることで初めて目的のHTMLに到達できる仕組みです。
2. doAction()関数とCNAMEチェックの仕組み
JRA公式サイトのページ遷移には、JavaScript関数doAction()が重要な役割を果たしています。この関数はユーザーのクリック操作を捕捉し、内部でフォームを用いたPOSTリクエストを送信することでページ遷移を実現しています
ken3memo.hatenablog.com
ken3memo.hatenablog.com
。具体的な仕組みと仕様は以下のとおりです。
doAction関数の定義：ページ共通のJavaScriptファイル（例：common2.js）内で定義されています
ken3memo.hatenablog.com
ken3memo.hatenablog.com
。定義内容を見ると、function doAction(url, cname)というシグネチャで、以下の処理を行っています
ken3memo.hatenablog.com
:
隠しフォーム<form id="commForm01" method="POST">内の<input type="hidden" id="cname" name="cname">に、引数で渡されたcname値をセットする
ken3memo.hatenablog.com
。
上記フォームのaction属性に、引数で渡されたurl（遷移先パス）をセットする
ken3memo.hatenablog.com
。
フォームcommForm01をsubmit()（送信）することで、HTTP POSTリクエストを発行する
ken3memo.hatenablog.com
。
return false;で<a>タグ本来の遷移動作をキャンセルする（ページ遷移はフォーム送信で完結するため）
ken3memo.hatenablog.com
。
つまり、doActionはダミーのフォームを使った遷移を実装する関数です。JRA公式サイトでは予めページ内に以下のようなフォーム要素が用意されています
ken3memo.hatenablog.com
。
<form id="commForm01" method="POST" enctype="application/x-www-form-urlencoded">
    <input type="hidden" id="cname" name="cname" />
</form>
doAction()はこのフォームに対して遷移先URLとパラメータ（CNAME）をセットし、POST送信する役割を担います
ken3memo.hatenablog.com
ken3memo.hatenablog.com
。なお、サイト側のコメントでは「渡されたURLとCNAMEパラメータを元にダミーFORMをSUBMITする。CNAMEはProxyCGIに渡すパラメータ」と説明されています
ken3memo.hatenablog.com
。ここから、サーバ側ではProxy用のCGIがこのCNAME値を受け取り、適切なコンテンツを生成していることが伺えます。
リンクの実装パターン：前述の通り、トップページや一部の遷移では<a href="#" onClick="doAction(...);">という形式が使われています。この場合、静的なhrefではなくJavaScript経由でPOST遷移するため、ブラウザの「ページのソースを表示」では遷移先URLが直接見えない仕組みです
doanythings0.blogspot.com
doanythings0.blogspot.com
。スクレイピングする際には、このonClick属性からdoAction呼び出しの引数を抽出する必要があります。例えばトップページのHTMLから以下のようなリンクが見つかります
doanythings0.blogspot.com
。
<a href="#" onClick="doAction('/JRADB/accessO.html','pw15oli00/6D')">オッズ</a>
上記では第1引数が/JRADB/accessO.html（オッズページのパス）、第2引数がpw15oli00/6DというCNAMEコードです
doanythings0.blogspot.com
。「レース結果」のリンクであれば同様にdoAction('/JRADB/accessS.html','pw01sli00/AF')という形になっています
doanythings0.blogspot.com
。したがって、HTML上から遷移先を知るには、文字列中からdoAction(で始まるJavaScript呼び出しを検出し、正規表現などでパラメータを抜き出す必要があります。例えばスクレイピングでは次の正規表現が利用できます
doanythings0.blogspot.com
。
ACTION_ARGS = re.compile(r'.*doAction\(([^,]*),([^)]*)\).*')
これでonClick属性中のURLとCNAMEを取り出し、Python側でrequests.postを使って同等のPOSTリクエストを送信することが可能です
doanythings0.blogspot.com
doanythings0.blogspot.com
。実際、ブログの有志による解析では、requestsを用いてdoActionと同等の処理を行う関数が定義されており、requests.post('http://jra.jp/'+arg1, data='cname='+arg2)のようにPOSTすることで遷移先HTMLを取得しています
doanythings0.blogspot.com
doanythings0.blogspot.com
。
CNAME（シーネーム）チェック：doActionで送信される隠しパラメータcnameこそが各ページ遷移を許可・識別するキーとなっています。CNAMEは「JRA内部データを取得するためのレース固有のコード」であり、ページ保護の一環としてセッション的な役割も果たしていると推測されます
jinseimosaku.com
jinseimosaku.com
。具体的には、サーバ側のCGIがこのcname値をチェックし、正しい組み合わせでなければデータを返さない仕組みです。CNAMEコードは一見ランダムな英数字ですが、一定の規則に従って生成されており、例えば先頭の数文字でコンテンツ種別（出馬表D、オッズO、結果S等）、次の数字で競馬場コードや開催回次、開催日などがエンコードされています
doanythings0.blogspot.com
doanythings0.blogspot.com
。もっとも、末尾の2桁程度はチェックディジットのような不明部分があり、単純には推測できないようになっています
doanythings0.blogspot.com
。実際の例では:
pw01sli00/AF – 「レース結果」トップメニュー用のCNAME（固定値に近い）
pw01srl10_06_2020_01_08_2020_01_25_/56 – 「レース結果」の開催選択用CNAME一例（競馬場コード06、開催開始日2020/01/08、終了日2020/01/25を含み、末尾/56が不明部分）
doanythings0.blogspot.com
。
pw01sde1006202301061120230115/48 – 個別レース結果用CNAME一例（内容の詳細は後述）
ken3memo.hatenablog.com
。
サイト側は、これらCNAME値が予め用意された有効な値であることを前提にページを表示します。もし不正確な組み合わせや無効なCNAMEでアクセスした場合、おそらくエラー画面やトップページへのリダイレクトとなるでしょう。CNAMEチェック機構により、ユーザーがURLを直接推測して飛ぶことを防ぎ、必ず公式サイト内のリンク遷移（＝doAction経由）を踏ませる意図があると考えられます。このようにセッション管理的な役割をCNAMEが果たすことで、自動巡回や直リンクを一定程度抑止する仕組みになっています。
HTMLへの埋め込み場所と抽出：doAction関数本体は先述のように共通JS内に定義されるため、実際のHTML（例えばトップページのソース）には登場しません。したがって、その存在はブラウザの開発者ツールでスクリプトを読み込んだ後に確認するか、または公式サイト内のどこかに掲載されているコードを参照する必要があります。Ken3氏の調査では、common2.jsにdoActionの定義が含まれていることが報告されています
ken3memo.hatenablog.com
ken3memo.hatenablog.com
。一方、各リンクに埋め込まれたonClick="doAction(...)"はHTMLソース上で確認できるため、スクレイピング時はこちらを手がかりに抽出します。抽出には前述のように正規表現か、BeautifulSoupで属性検索（例：soup.find_all(attrs={"onclick": re.compile(r'doAction')})）を行う方法が考えられます
doanythings0.blogspot.com
doanythings0.blogspot.com
。なお、一部のページではreturn doAction(...);という記法になっている場合もあります（これは<a>クリック後にfalseを返してデフォルト動作を止めるため）ので、正規表現ではreturnの有無や空白にも対応できるパターンにしておく必要があります
doanythings0.blogspot.com
。
以上のように、doAction()とcnameはJRAサイトの動的遷移における中核要素です。ユーザー側から見ると「リンクをクリックすると次ページが表示される」だけですが、その裏ではこの関数によるPOST送信と、サーバ側でのCNAME認証を経てコンテンツが配信されています。この仕組みを正しく理解・再現することが、スクレイピングにおいて必要不可欠となります。
3. race_id（12桁）から直接URL生成できない理由と遷移手順の必要性
JRAの各レースには内部で12桁のrace_id（例: 202405020411）が割り振られており、その中には年・開催・日・レース番号といった情報がエンコードされています。例えば「2024年5回東京2日目11レース」のrace_idは202405020411となります（YYYY=2024, 開催=05, 日=02, レース番号=11）。一見すると、このrace_idさえ分かれば対応するレース結果ページのURLを構築できそうに思えます。しかし、実際にはrace_idから直接レース結果ページのURL（および必要パラメータ）を生成することはできません。その論理的根拠と理由は以下の通りです。
URLにrace_idが含まれない：JRA公式のレース結果ページURLは前述したようにaccessS.html?CNAME=...という形式であり、race_idそのものはURLのどこにも現れません。従って、単純に「race_idをURLに埋め込んでアクセスする」ということができません（例えばnetkeibaのように.../race/{race_id}というパスは提供されていません）。公式サイトはrace_idではなくCNAMEコードでページ遷移を管理しているため、race_id→CNAMEの変換が必要になります。
CNAMEコードの不明部分：CNAMEにはレースを特定する情報が含まれていますが、その生成規則が完全には公開されていません。前述した通り、CNAMEの後半数桁は一種のチェックディジットや暗号的な値になっており、単純な規則ではありません
doanythings0.blogspot.com
。実際、有志の解析者たちも「後ろ3桁の作り方がいまいち分からない」と述べており、自力でCNAMEを計算する試みは挫折しています
doanythings0.blogspot.com
ken3memo.hatenablog.com
。Ken3氏の調査でも、例示されたCNAME（pw01sde1006202301061120230115/48）の規則性が掴めず「お力になれずすみません」というコメントが残されています
ken3memo.hatenablog.com
。このようにrace_idから対応するCNAMEを導く公式が不明なため、race_id単独では直接のページ呼び出しに必要な情報が不足しています。
中間ページ・セッションの存在：race_idはあくまでデータベース上のキーですが、公式サイトではまず開催情報ページ→レース一覧ページを経て初めて各レースのCNAMEが得られる設計です。言い換えれば、CNAMEはそのレースが属する開催ページを経由しないと取得できないようになっています。特定のrace_idに対応するCNAMEだけを知っていれば、プログラム的には直接POST/GETして結果ページを取得できる可能性はあります。しかし、そのCNAMEを得るためには結局該当開催日のページを開いてHTMLを解析する必要があります。サイト側も、それを踏まえ直接リンクを提供しない作りにしていると考えられます。レース一覧ページには当該開催の全レースのCNAMEが埋め込まれており、まずそこにアクセスすることでしか個々のCNAMEが判明しません。
動的生成・有効期限の可能性：CNAMEコードは各レースごとに固定のようにも見えますが、内部的には生成されるタイミングや有効期限がある可能性も否定できません。例えば開催前と開催後で値が変化する、あるいは毎年リセットされる等です（※厳密な挙動は不明ですが、Excelソリューションの例では「毎回異なるコードが発行される」とも述べられています
jinseimosaku.com
jinseimosaku.com
）。仮にrace_id→CNAMEの対応表を以前に取得していても、新たなレースでは再度取得し直す必要があるかもしれません。この不確定要素も、「race_idだけでは直接アクセスできない」一因と言えます。
以上の理由から、スクレイピングではrace_idから直接結果ページURLを構築するのではなく、必ず公式ページの遷移フローを踏襲する必要があります。具体的には、「カレンダー → 開催日 → レース一覧」を順に辿って目的のレースのCNAMEを入手し、その上で結果ページを取得する手順となります
doanythings0.blogspot.com
doanythings0.blogspot.com
。この手順を怠って無理にURL生成を試みても、CNAMEコードのずれにより失敗するか、誤ったデータを参照するリスクがあります。実際、多くの先行事例で**「素直にトップページからたどるのが一番確実」**との結論に至っており
doanythings0.blogspot.com
、race_idから直接飛ぶアプローチは取られていません。 なお、race_idはデータベース的な一意識別子としては有用なので、取得した結果データを保存・管理する際にはrace_idをキーとして用いることが推奨されています。しかしあくまで結果ページ取得の入口はCNAMEであり、スクレイピング上はrace_id→CNAME引き当てのための前処理（ページ遷移）が必須となる点に注意が必要です。
4. カレンダー／開催日／レース一覧 各ページのHTML構造とリンク抽出方法
前節までの説明で、レース結果ページに到達するまでに複数の中間ページが存在し、それぞれにレースリンクの情報が埋め込まれていることが分かりました。本節では、それぞれのページのHTML構造上の特徴を分析し、目的のリンク（レース結果ページへのパスやCNAME）を取得するための具体的手法を示します。スクレイピングではBeautiful Soup等のHTMLパーサを利用することを想定し、適切なCSSセレクタや正規表現の例も挙げます。
開催日程ページ（カレンダー）の構造：開催日程（月間カレンダー）は、おそらく<table>タグで構成されたカレンダー形式のHTMLです。各<td>（日付セル）内に、その日に競馬開催がある場合はリンクが挿入されています。リンクテキストは日付もしくは開催情報（例：「11. 東京 京都 …」など）で、リンク先は開催日ページ（次の階層）です
jra.go.jp
。このページでは、セル内の<a>タグを走査し、href属性から開催日ページへのパスと対象日情報を取得します。リンク先はJavaScript経由の場合と直接hrefの場合がありますが、多くは静的リンクになっていると推測されます。抽出例：BeautifulSoupでcalendar_table = soup.find('table', class_='calendar')のようにカレンダーテーブルを特定し、さらにcalendar_table.find_all('a')で全リンクを取得します。その際、リンク先URLに開催日識別情報（例えば.../20230524.htmlのようなパス）が含まれるので、それを解析して日付を特定します。テキストにも日付が含まれるのでクロスチェックできます。
開催日ページ（特定日・全開催一覧）の構造：開催日ページでは、その日付に行われる全競馬場の開催がリスト化されています。例えば2025年5月24日なら「2回東京9日」「2回京都9日」等が箇条書きまたは表で表示されています
jra.go.jp
。HTML的にはシンプルで、各開催名が<a>タグになっているか、またはテキストと同じ行に「レース結果」「出馬表」等のリンクが並ぶ形式も考えられます。実例として、京都と東京の開催が並んだページ断片では、リンクテキストとしてそれぞれの開催名が表示され、そのリンク先はおそらくaccessS.htmlにCNAMEパラメータを付与したURLになっています
jra.go.jp
（サイト構造によりますが、Ken3氏のブログからは<a href="/JRADB/accessS.html?CNAME=...">2回東京9日</a>という例が確認できます）。このページから各開催のレース一覧ページへのリンクを抽出するには、リンクテキストが「○回○○○○日」にマッチする<a>要素を探せば良いでしょう。CSSセレクタ例：a[href*="accessS.html"][href*="CNAME="]かつテキストに正規表現r'\d+回.+'を当てる方法が考えられます。実際、スクレイピングのコード例では、BeautifulSoupでpage.select('div.content a[href="#"][onclick*="doAction"]')の中からテキストが「○回◯◯◯◯日」に当たるものを抽出しており
doanythings0.blogspot.com
、その結果以下のようなリスト（開催名とCNAMEのペア）を得ています
doanythings0.blogspot.com
。
[
    ('/JRADB/accessS.html', 'pw01srl10052020010120200201/C2', '1回東京1日'),
    ('/JRADB/accessS.html', 'pw01srl00082020020220200202/D8', '2回京都2日'),
    ...
]
（※上記はオッズページの例ですが、レース結果でも同様にaccessS.htmlとsrl系のCNAMEが取得できるはずです。）このように、開催日ページでは各開催ごとの**一覧ページへのCNAMEコード（...srl...）**が埋め込まれているので、これらをすべて抽出します。
レース一覧ページ（当日レース一覧）の構造：レース一覧ページには、その開催日・競馬場における全レース（通常1～12R）の情報が表形式で掲載されています。HTMLでは<table id="race_list">等のテーブルがあり、各行（<tr>）が1レースを表します
doanythings0.blogspot.com
。列構成の一例は、発走時刻（時刻表示 or 「発走済」）、レース番号（ボタン形式）、レース名（本賞典名・副題）、条件（馬齢・クラス・重量など）、各種リンク（出馬表・オッズ・結果・払戻など）です
doanythings0.blogspot.com
。近年のサイトでは各リンクがリスト形式で表示されており、例えばあるレースの「オッズ」リンクは<li class="odds"><a ...>オッズ</a></li>のようになっています
doanythings0.blogspot.com
。「レース結果」も同様に<li class="result"><a ...>レース結果</a></li>となっているか、もしくはレース番号部分自体が結果ページへのリンクになっている場合があります。Ken3氏の報告では、レース番号セル（th.race_num）内のリンクが直接レース結果ページ（accessS.html?CNAME=...）を指している例が見られました
ken3memo.hatenablog.com
。つまり、レース一覧ページ上で既に各レースの結果ページCNAMEが取得可能ということです。 抽出方法としては、まずテーブル内の各行をパースし、その中から「結果」リンクの要素を探します。前述のように、リンク実装が2パターン考えられるため、それぞれに対応します。
パターンA: レース番号セル全体が結果ページへのリンクになっている場合。⇒ この場合、各th.race_num aのhref属性を取得すればよいです
ken3memo.hatenablog.com
。hrefに含まれるCNAME=pw01sde...部分がそのレース固有の結果ページパラメータです。さらに、リンク内部のimg要素のaltからレース番号（例：「1レース」）が識別できます
ken3memo.hatenablog.com
。
パターンB: レース番号はテキスト表示で、別途「レース結果」列がありそこにリンクがある場合。⇒ この場合、各行の中からテキスト「レース結果」を持つ<a>を探すか、構造化クラスli.result aなどで探します。例えば、row.find('li', class_='result').a['href']のように取得できます。
抽出したhrefは/JRADB/accessS.html?CNAME=XXXXXという形式なので、「/JRADB/」を基にフルURLを組み立てるか、requests利用時にはベースURLに相対パスを付与してアクセスします。正規表現パターンで一括抽出するなら、r'accessS\.html\?CNAME=[^"]+'でページ全文からマッチさせる方法もありますが、意図しない重複を避けるため構造化解析が望ましいです。 また、このページでは例外的な表記として、レースが終了していない場合「出走取消」「競走中止」等の表示や、レースがまだ発走前の場合リンクが無効（表示のみ）になっているケースがあります。しかし最終的にスクレイピングする時点では全レース終了後と想定されるため、基本的に全レースに結果リンクが存在する前提で処理します（もしなければスキップされるだけです）。
各ページ共通の注意点（文字コードと解析）：JRAサイトはShift_JIS（厳密にはMS932）エンコーディングでHTMLを提供しています
doanythings0.blogspot.com
。requestsで取得した場合、自動判別されないこともあるため、必ずr.encoding = 'shift_jis'（またはr.contentをr.content.decode('cp932')でデコード）してから解析します
doanythings0.blogspot.com
。文字コードの問題で、例えば全角スペース（ ）が\xa0として残る、ハイフンマイナスが文字化けする等があります。これについては、解析時にstr.replace('\u00a0',' ')で通常スペースに置換する、適宜正規化するなどの対策が必要です。HTML構造自体は整っているため、BeautifulSoup＋lxmlでパースすれば日本語も含めて安定して抽出できますが、エンコーディング指定だけは忘れないよう注意が必要です（指定忘れによりダブルバイト文字が化けるケースが多々あります）。
以上が中間ページの構造と抽出方法の概要です。要約すれば、「カレンダーページから開催日リンクを、開催日ページから開催ごとのレース一覧リンクを、レース一覧ページから各レース結果リンクを順次取得する」ことになります。各段階で適切なHTML要素（<a>タグ）を探索し、埋め込まれたCNAMEコードを取り出すことで、最終的に各レース結果ページのURLパラメータを手に入れることができます。この一連の流れを自動化すれば、サイト構造に追従しながら全レース結果ページを収集できるわけです。
5. レース結果HTMLの構造解析：表組み・特殊表記・文字コードの影響
レース結果ページ（各レースの詳細ページ）は、本システムで収集すべき生データの宝庫です。そのHTML構造を正確に解析し、必要な情報を漏れなく抽出することが重要となります。本節では、レース結果ページの具体的な構造（テーブル配置やクラス属性など）、掲載される情報項目とその変則表記、Shift_JIS特有の文字問題について詳しく解説します。
ページ全体構成：レース結果ページには大きく分けてレース概要セクションと着順表（結果表）セクションがあります。レース概要には開催情報とレースの基本情報が記載され、着順表には出走各馬の成績が表形式で一覧化されています。例えばページ冒頭には見出しとして「2025年11月2日（日曜）4回東京11日 11レース」と表示され、その直下にレース名「○○ステークス（GIII）」や条件「サラ系3歳以上 （混合） 定量」、距離「芝1600m（左）」、天候「晴」、馬場状態「良」等がまとまって記載されています
jra.go.jp
。これらはHTML上では段落や定義リスト(<p>や<dl>)で記述されている可能性が高いです。実際、レース名は太字見出し(<h1>相当)として表示され、レース条件・天候等は改行区切りのテキストになっています。 レース概要部分で取得すべき主な情報は開催日（ページ自体から明らかですがデータ項目として保持）、競馬場・開催回・日次（例：「4回東京11日」）、レース番号、レース名、グレード（重賞ならGI/GII/GIII、リステッドならL表記）、距離、コース種別と回り（芝/ダート・左/右など）、天候、馬場状態、クラス・条件（例：3勝クラス、2歳限定など）です。これらはページ内にほぼテキストで載っており、例えば「天候:晴\n馬場状態:良」のように表示されています。Shift_JISでは「良」の文字が機種依存文字になることがありますが、UTF-8に適切にデコードされれば問題ありません。
着順表（結果表）の構造：着順表はHTMLでは<table summary="全着順">等として定義され、見出し行（カラムヘッダ）と各着順の行が並んでいます。PC向けサイトではカラム見出しに「着順」「枠番」「馬番」「馬名」「性齢」「斤量」「騎手」「タイム」「着差」「上がり3F」「単勝オッズ（人気）」「調教師」「馬体重（増減）」などが含まれていると推測されます。スマートフォン版の情報から類推すると、PC版でもこれらデータは全て提供されています
sp.jra.jp
。実際、スマホ版では1行に「馬名/単勝人気 性齢/馬体重 騎手(斤量)/調教師 タイム(着差)/上がり3F」という形式で詰め込まれていました
sp.jra.jp
が、PC版ではそれぞれが独立のカラムになっている可能性があります。 具体的な情報項目（および抽出上のポイント）は次の通り：
着順：1着、2着…の順位。数値で表示されます。同着の場合、公式サイトでは同じ順位を重複表示しつつ備考で「同着」と記載すると思われます（例：1着が2頭の場合、着順欄に「1」を2行並べる等）。棄権・失格などの場合、その馬の着順は「取消」や「失」と表示される可能性があります。この欄はテキストとして取得できますが、「取消」「失格」など文字列にも注意します。
枠番・馬番：枠番は1～8（中央競馬では最大8枠）、馬番はそのレースの出走頭数内での馬番号です。公式サイトでは枠番に枠色（白・黒・赤...）の背景または文字が付いており、テキストとしては「枠5黄」など色名付きで出力されるケースがあります
jra.go.jp
jra.go.jp
。実際のHTMLでは、枠番はCSSで背景色を付けるか、<span class="waku w5">5</span>のような構造かもしれません。検索インデックスには「枠5黄, 7, 馬名...」といった文字が出ており、おそらく「枠5黄」は視覚的には「5枠（黄）」を意味します
jra.go.jp
。スクレイピングでは枠番と馬番は別々に取得して数値化します（色名は不要なので削除可）。HTML上で枠番はセルに入っているだけなら、そのテキストを数字部分だけ取る、あるいは画像が使われているならalt属性から取る方法もあります。
馬名：馬の名前。馬名は基本テキストですが、リンクになっています。JRAサイトでは各競走馬名が「競走馬情報ページ」へのリンク（/JRADB/datafile/horse/{数字}.html）になっており、これをクリックするとその馬のプロフィールが表示されます。HTMLでは<a href="/JRADB/datafile/horse/012345.html">馬名</a>のようになっており、このリンクから馬の固有ID（例では012345）を抽出できます。スクレイピング時は馬名テキストとhorse_idの両方を取得しましょう（horse_idはURLから正規表現/horse/(\d+)\.htmlで抜き出せます）。なお、外国産馬名などで記号「*」や「◯外」等が付くことがありますが、これは馬名の一部として扱われます（文字化けしないよう注意）。
性齢：性別（牡・牝・セ）と年齢を組み合わせたもの。例えば「牡4」は4歳牡馬を意味します。テキストで「牡4」「牝3」のように表示されています。ここも全角数字や漢字が混在するため、そのまま文字列取得後、性と年齢を分離します。年齢は半角数字か全角数字か確認し、必要なら変換します。
斤量（騎手の負担重量）：騎手が背負う重量(単位: kg)。これは通常騎手名の後ろに括弧書きで表示されます（例：「福永祐一(57.0)」）
sp.jra.jp
。PC版では斤量が独立列になっているか、騎手名と同じセル内に括弧で書かれているか定かではありません。スマホ表示では騎手と斤量は一体化していました
sp.jra.jp
。解析では、騎手名から括弧内の数字を抜き出すことで斤量を取得できます。斤量には小数点がつく場合（例：障害競走では騎手重量+2kgなど）もありますが、通常は整数か「0.0」刻みです。
騎手名：騎乗した騎手の氏名。これもリンク付きで、JRA騎手情報ページ（/JRADB/datafile/jockey/{番号}.html）へのリンクになっています。リンクの取り方は馬名と同様で、URLからjockey_id（例：01085）を取得可能です。騎手名自体はテキストで取れます。なお、見習い騎手の減量区分（☆や△）は名前に含まれる可能性があります（例えば「菅原明良☆」など）。この場合、その記号もテキストに現れるので、必要に応じて除去しても良いでしょう（データベース上は区別せずIDで管理するため）。
調教師名：管理する調教師の氏名。これもリンク付きで、調教師情報ページ（/JRADB/datafile/trainer/{番号}.html）へのリンクです。騎手と同様に、trainer_idをURLから取得できます。調教師名の後ろには所属（「(栗東)」「(美浦)」などトレーニングセンター）が括弧書きで表示されます
sp.jra.jp
。例えば「矢作芳人(栗東)」のようになります。HTMLでは括弧込みのテキストとなっているため、パース後に括弧内を切り出せば所属情報も取得可能です（データ分析で東西の特徴を見る際に有用です）。ただしv4スキーマでは所属は特にフィールドとして要求されていないため、必要に応じて保持する形になります。
タイム：勝ちタイム（および後続馬のタイム）。1着馬についてはレースの走破タイム、2着以下については1着との差（着差）を踏まえた所要タイムになります。サイト上は1着馬には「1:34.2」等のタイム、2着以降には基本的にタイム差（「クビ」「3/4」「1.2」秒等）が表示されることがあります。JRA公式の結果表では、2着以下のタイム欄も着差表記ではなく到達タイムそのものを載せています（※着差は別欄にあるため）
sp.jra.jp
。したがって各馬固有のタイム欄があり、1着馬＝基準タイム、以下は自動的に計算可能ではありますが、一応テーブルには全馬のタイムが掲載されます。スクレイピングでは文字列としてタイムを取得しますが、注意点として「レコードタイ」が出た場合「R」マークが付く、同着がある場合「同着」表示がある、競走中止の場合「--.-」のようにタイムが欠損するなど特殊ケースがあります。例えば「タイム：1:07.8R」のようにタイム末尾にRが付与されるケースでは、文字上そのままだと数値変換できないため、Rを除去する必要があります。
着差：各馬の着差。1着馬には当然着差はありませんが、通常ハイフンや空欄になるか、「–」で表現されます。2着以下には「クビ」「1/2」「大差」など日本語表記や分数表記があります。Shift_JIS環境では「クビ」は問題ないですが、「1/2」はスラッシュで区切られた半角文字列でこれが1/2とそのままHTMLに書かれていると、BeautifulSoupでテキスト抽出すると「1/2」となり、Pandas等で読込むと日付と誤解されることがあります（実際、ExcelやPandasで読み込むと1月2日と解釈される事例が報告されています
note.com
note.com
）。この対策として、着差は文字列として保持し、後で「1/2→0.5」と変換するなど明示的な処理を行うと安全です。また「同着」の場合、同じ着差欄に「同着」と表示されることも考えられます。
上がり3F：各馬の最後の600m（3ハロン）のタイム。通常、JRA公式結果には全馬の上がりタイムが掲載されます。PC版でも「上がり3F」または「上り3F」というカラムがあり、例えば「33.7」のような数値が入ります。先行した馬ほど遅く、後方待機馬ほど速い値になる傾向があります。スクレイピング時は文字列で取得し、小数点付きの秒数として扱います。注意：小数点が「.」か「．」（全角ピリオド）かを確認します。おそらく半角ピリオドですが、エンコーディングによっては0x818Fの全角ピリオドになる可能性があります。その場合は適宜置換が必要です。
単勝オッズ・人気：単勝式の最終オッズと人気順です。JRA結果ページでは「単勝」もしくは「単勝オッズ」「人気」という表示で提供されます。スマホ版では馬名の右に「1番人気」等と記載されていたので、PC版ではオッズと人気が別カラムになっているか、もしくは「オッズ(人気)」のようにまとめられている可能性があります。v4スキーマ上はオッズと人気を別フィールドで保持しますので、それぞれ取得します。HTMLでは、人気は数値（整数）で、オッズは少数第1位まで（例えば3.5倍なら「3.5」）で表記されます。1倍未満のオッズは理論上ありませんが、1.0x倍になるケースがあります（人気馬で極端に売れた場合）。オッズは小数点を含むため、文字列→float変換時にピリオドが全角でないか気をつけます。※サイトによりオッズは全角数字+小数点で表記の例もありましたが、JRA公式は半角数字と思われます。なお、オッズと人気は結果ページ内に含まれるため、オッズページへの追加アクセスは不要です。
馬体重（増減）：馬の当日馬体重と、前走からの増減値です。公式結果では通常「馬体重(増減)」の形式で表示されます
sp.jra.jp
。例えば「456(-8)」なら当日456kgで前走比-8kgという意味です。これもテーブルの一列として存在します。取得後は括弧内を分離し、馬体重と増減数値に分けて保持すると便利です。なお、新馬戦（前走なし）の場合や前走が海外の場合、増減が「---」等となるケースがありますが、そのまま文字で扱えば問題ありません。
追加情報・特殊表記：着順表の下またはページ下部には、レースに関する付記事項や制裁情報が記載されます。例えば「○○号は発走除外」、「△△号の騎手◇◇は安全騎乗義務違反で過怠金○○円」等の文章です
jra.go.jp
。これらはおそらく<div class="remarks">や<ul class="notes">のような領域にリストまたは段落で記載されます。予測モデルの主要データには直接関係しないため、v4では収集対象外かもしれませんが、興味があればテキストとして抽出・保存できます。文字コード的には漢字かな混じりの日本語なので問題なく取得できますが、人名等が含まれるため解析は慎重に（騎手名と同姓同名の区別など）扱う必要があります。
Shift_JISエンコーディングの影響：前述したように、Shift_JISで提供されるため、特定の文字がUTF-8にない独自符号化となっている場合があります。代表例は「①②…⑫」の丸数字ですが、レース結果では使われないでしょう。むしろ気を付けるべきは全角記号です。例えば馬名中の「○外」（丸外）や、「▲」（見習い騎手減量記号）、「★」（更に大きな減量）などはJIS非漢字でShift_JIS上の特殊コードになります。変換時に文字化けする可能性があるので、念のためこれら記号も正しく表示されているか確認します。幸いrequests＋BeautifulSoup(lxml)では適切にr.encoding='shift_jis'を指定すれば大抵問題なくUnicode文字列に変換されます
doanythings0.blogspot.com
。しかし、もし異常が見られる場合、r.content.decode('cp932', errors='ignore')のようにマイクロソフト版コードページでデコードする手もあります。 また、スペースや特殊空白にも注意です。JRAページではレース条件等の区切りに**ノーブレークスペース（ ）**を使うことがあり、例えば「3歳以上　(混)　定量」のような箇所に普通の空白ではなく特殊空白が入っています（実際、解析時に\xa0として現れることがあります
doanythings0.blogspot.com
）。これを放置すると文字列比較やsplitが想定通りに動かないため、前処理で\u00A0を通常の空白に置換するか削除するのがおすすめです。たとえばPythonでtext.replace('\u00a0',' ')のようにできます。
以上、レース結果ページのHTML構造とデータ項目について網羅的に説明しました。このページからは予測モデルに必要なほぼすべての原データが取得可能です。ただし、複雑な表記やエンコーディングの点で注意すべきポイントも多々あります。実装に当たっては、まず一つのレースで全項目を正しくパースできるか確認し、特殊ケース（同着・中止・レコードなど）にも対応できるよう条件分岐や正規化処理を組み込むと良いでしょう。
6. 「1ページのみで抽出できる生データ一覧」とv4スキーマの対応
v4スキーマにおいて定義されているデータ項目のうち、JRA公式のレース結果ページ1枚から自動抽出可能なものと、ページ単独では取得できないものを整理します。v4では「Must（必須）」「Should（可能なら）」の区分で項目が設計されていますが、本システムではJRA公式結果ページのみを一次ソースとし、追加取得が必要な項目はスコープ外とする方針です。そのため、基本的には「ページ1枚から取れるもの」だけをデータベースに取り込むことになります。以下に主要項目を挙げ、抽出可否を明記します。
開催情報・レース概要に関する項目（レーステーブル）:
開催日（年月日） – 抽出可。ページ見出しやパンくずに日付が記載されており取得可能です。
開催（何回・何日目・競馬場） – 抽出可。見出しに「4回東京11日」のように表示あり
jra.go.jp
。
レース番号 – 抽出可。見出し等から取得可能。
レース名（重賞番号含む） – 抽出可。ページ内に明記
jra.go.jp
。
グレード（GⅠ/GⅡ/GⅢ/L） – 抽出可。レース名に付帯表示。重賞であれば括弧書きで記載
jra.go.jp
。
距離 – 抽出可。「芝2000m」「ダート1200m」等テキストで記載。
コース（芝/ダート・左/右/直） – 抽出可。距離表記に続けて「（左）」「（右）」「（直線）」「外回り」等と記載。解析して標準化が必要ですがページから取得は可能です。
天候 – 抽出可。天候:晴 等と記載。
馬場状態 – 抽出可。馬場状態:良/稍重/重/不良 が記載。
クラス（競走クラス） – 抽出可。条件欄に例えば「3勝クラス」「GIII」「オープン」等が記載。
年齢条件 – 抽出可。「3歳以上」「2歳」など。
性別条件 – 抽出可。「（牝馬限定）」等の記載。混合の場合は特に注記無し。
重量条件 – 抽出可。「定量」「ハンデ」「馬齢」等の記載。
出走頭数 – 抽出可。結果表の行数やページ上部に「（出走12頭）」のような記載がある場合取得。無い場合でも結果表から行数カウントで把握可能です。
各馬の成績に関する項目（レース結果テーブル）:
着順 – 抽出可。全着順表から取得。数値または特定文字列（取消等）。
同着フラグ – 抽出可。着順の重複や備考「同着」から判断可。必要なら生成。
枠番・馬番 – 抽出可。結果表に明記。
馬名 – 抽出可。リンクテキストとして存在。
馬ID（horse_id） – 抽出可（リンクから抽出）。例：.../horse/012345.html→012345。
性別・年齢 – 抽出可。性齢欄から。
斤量（負担重量） – 抽出可。騎手名の括弧内または独立欄から。
騎手名 – 抽出可。リンクテキストとして存在。
騎手ID（jockey_id） – 抽出可（リンクから抽出）。例：.../jockey/01085.html→01085。
調教師名（所属） – 抽出可。リンクテキスト＋括弧で所属付きで存在。
調教師ID（trainer_id） – 抽出可（リンクから抽出）。例：.../trainer/01123.html→01123。
タイム – 抽出可。文字列（mm:ss.d）で取得。
着差 – 抽出可。「クビ」「1.1」など取得。変換は別途。
上がり3F – 抽出可。全馬分取得可。
単勝オッズ – 抽出可。小数で取得可。
人気順 – 抽出可。整数で取得可。
馬体重 – 抽出可。整数で取得可。
馬体重増減 – 抽出可。括弧内±数値を取得可。
コーナー通過順位 – 抽出可（ページ内に記載）。各コーナー毎の通過順序がテキストで載っており、パース可能です。
レース備考（制裁など） – 抽出可。テキスト段落として取得可能。
以上列挙した通り、v4スキーマで「Must」と位置付けられ主要な予測変数となる項目は、すべてレース結果ページ1枚から取得可能です。例えば馬・騎手・調教師の各IDも、結果ページ内のプロフィールリンクから引けるため追加のページ遷移は不要です。これはv4の重要方針「別ページへの追加取得を行わない」に合致しています。また「Should（あれば望ましい）」レベルの項目についても、上がりタイムやオッズなどは網羅できています。 一方、結果ページだけでは取得できない情報もいくつかあります。それらは本システムでは扱わない（NULLで保持するか、後続バッチで補完）方針です。具体例：
前走情報（各馬の前回出走レースや着順など） – 結果ページには掲載なし。v4ではprev_race_id等を持たせていますが、ETL直後はNULLとし、別途過去データからリンク付けする設計です。
払戻金情報（各式別の配当） – これは**別ページ（払戻金ページ）**に記載されており、結果ページには載っていません。従って取得しません（必要ならaccessH.htmlにアクセスが必要だがv4では対象外）。
ラップタイム（各ハロンの通過タイム） – 結果ページには載っていません（「レース成績表PDF」等を参照する必要あり）ため抽出不可。
その他詳細（天候の詳細、発走時刻（秒単位）、入線順と確定着順の差異 等） – 基本的にページ記載がないものは扱いません。
以上をまとめると、「1ページで抽出できる生データ一覧」は前節で述べた通りであり、それがそのままv4スキーマのカラムに対応しています。抽出可否としては、Must項目は全て○、Should項目も概ね○で、一部（前走・払戻など）のみ×となります。v4設計時点で、取得困難な要素はスコープから外されているため、実運用上は公式ページ1枚をパースするだけで必要十分なデータが揃う想定になっています。これは非常に効率的かつ一貫性のあるデータ収集を可能にしており、追加でnetkeiba等他サイトに頼る必要もありません。
7. ETL処理各段階の難所と対策
本ホワイトペーパーの対象であるJRA公式レース結果データを用いたETL（Extract→Transform→Load）のプロセスにおいて、想定される難所とその対策を整理します。ETLフェーズごとに課題を洗い出し、安定したデータ取得・蓄積を実現するための工夫を述べます。
Extract（抽出段階）の難所と対策
抽出段階では「いかにして目的のHTMLページを取得するか」がテーマになります。難所となるポイントと対策は以下です。
多段階のアクセスが必要：前述のように、直接目的のページURLが分からないため、カレンダー→開催日→レース一覧→結果と複数リクエストを連鎖させる必要があります。これによりリクエスト数・通信量が増大し、時間もかかります。また、途中のどこかで失敗するとそのレースまで到達できません。対策：可能な限り自動化してエラー処理を入れておくことです。例えばPythonスクリプトで、一日の全レースを順に辿るループを組み、各ページ取得に成功したかチェックします。失敗したらリトライを一定回数行い、それでもだめならログに記録して次へ進む処理を加えます。また、開催スケジュールを事前に取得しておき、存在しない開催やレースにはアクセスしない工夫も有効です。例えばJRA公式の年間開催日程をパースしてrace_idリストを構築し、それに沿って抽出する方法なら、無駄なリクエスト（存在しないIDへのアクセス）を減らせます。
JavaScript遷移の再現：doActionによるPOST遷移をサーバ側で再現する必要があります。直接GETでも動くケースがありますが確実ではないので、基本はrequestsでPOSTするコードを自前で書くことになります
doanythings0.blogspot.com
。対策：第2章で述べたdoAction相当のPython関数（requests.postを使ってcnameを送る）を用意して、リンク抽出→即POSTリクエストという処理を組みます
doanythings0.blogspot.com
。requestsはセッションを維持できるので、with requests.Session()を使うとCookieや接続を引き継げて効率的です。一方、最近の傾向ではGETパラメータでもアクセス可能なようなので、CNAME付きURLを直接GETする方法もテストしてみて有効なら採用します（これが可能なら実装はかなり簡略化されます）。Ken3氏の例ではaccessS.html?CNAME=...へのhrefリンクが実際に存在し、それをクリックするとページが表示される（=GETリクエストしている）ことが確認されています
ken3memo.hatenablog.com
ken3memo.hatenablog.com
。このため、requests.getで直接結果ページを取得できる可能性が高く、その場合POST再現は必須ではなくなります。検証した上で、GETで問題なければ以降はGETに統一するのも手です。
アクセス頻度とサーバ負荷：JRA公式とはいえ大量の機械的アクセスは歓迎されません。特に開催数×レース数の全件取得を頻繁に行えば、サーバに負荷を与え、最悪ブロックされるリスクもあります。対策：アクセス頻度を抑えるポリシーを持つことです。具体的には、(a)必要なデータのみ取得する（例えば過去データは一度取ったら保存し再取得しない）、(b) リクエスト間にディレイを入れる、(c) 夜間などアクセスが少ない時間帯に実行する、等です。例えば1レース取得ごとに1秒スリープを入れるだけでも、1日あたり最大で12秒×開催数の遅延となり十分負荷軽減になります。JRA側のrobots.txtにはスクレイピング禁止の明記は見当たりませんが（要確認）、あくまで「公式サイトをお借りしている」という意識でマナー遵守が必要です。
通信エラー・タイムアウト：大量ページ取得では、ネットワーク不調や一時的なサーバ応答低下でタイムアウトが発生する可能性があります。対策：requestsのtimeoutオプションを適切に設定し（例：10秒）、例外処理を実装します。一定回数までリトライしたり、プロキシやIPを変えて試す仕組みも有効です。さらに、万一に備え途中まで取得したデータを定期的に保存（チェックポイント）することで、再実行時にスキップできるようにすると良いでしょう。
HTML保存による再取得防止：抽出段階のもう一つのポイントは、一度取得したHTMLを保存して二度と同じものを取りに行かない工夫です。v4では「スクレイピング再実行を避けるため、必ずHTMLを保存する」としています。対策：各レース結果ページを取得したら、そのHTMLソースをファイルに保存する（例：data/raw/jra/race_{race_id}.html）ことを徹底します。メリットとして、後で解析ロジックを修正したくなった際に再度サイトにアクセスする必要がなくなります。これはサイト構造変化にも強く、過去分のHTMLが手元にあれば、新仕様のパーサを書くだけで再変換できます。ストレージ容量とのトレードオフですが、テキストなのでさほど大きくなく（年間数千レースでも数十MB程度）問題ありません。
Transform（変換段階）の難所と対策
変換段階では、取得した生HTMLを解析してデータ項目を取り出し、所定のデータ型・フォーマットに整形します。この段階の難所は主にパースとデータクレンジングにあります。
HTMLパースの信頼性：BeautifulSoupやlxmlでHTMLをパースする際、サイト構造の変化やHTMLの不整合があると正しく要素が取れない恐れがあります。JRA公式は比較的整ったHTMLですが、年次リニューアルなどで構造が変わるリスクがあります。対策：パースには極力頑健な方法を取ります。具体的には、テーブルの列順に強く依存しないよう列名やクラス属性をキーにデータ取得することです。例えば結果表のヘッダ行から各列の位置を特定し、そのindexで行データを読む方法だと、列順変更に弱いです。代わりに、各セルに適切なclassやscope属性が付与されているなら、それを利用して抽出します（例：row.find('td', class_='time').textでタイム列取得
doanythings0.blogspot.com
）。もしそれが無い場合でも、カラム数チェックやヘッダ名キーワード検索で列を認識する柔軟性を持たせます。変化があった際はエラー検知しやすいよう、想定外のHTMLパターンの場合にはログに警告を出すようにしておくと良いでしょう。
数値・文字列変換と単位：抽出したテキストデータをそのままではなく、整形して保持する必要があります。難所として、全角→半角変換、単位文字の除去、日付・時刻のフォーマット変換などが挙げられます。対策：Transform段階で専用のクレンジング関数を各項目ごとに設けます。例：
馬体重「456(-8)」⇒ weight=456, diff=-8 に分割。数値化。
タイム「1:07.8」⇒ 分:秒を秒単位に換算、またはそのまま文字列保持。後続分析のしやすさで決めます。例えば67.8秒と数値で持つと計算は楽ですが、人に見せるには元フォーマットが良い。v4では文字列で保持する選択肢もあります。
着差「3/4」⇒ 0.75に変換、または「0.3」秒相当に換算。（ただしJRAの着差は公式に長さ表示なので、そのままテキストでもよい。）クビやアタマは距離として扱いづらいので、便宜上「0.1秒」「0.05秒」等にマッピングする手もありますが、ここはモデル利用目的によります。
オッズ「12.6」⇒ 12.6 (float)に。人気「1番人気」⇒ 1 に。
日付「2025年5月24日」⇒ "2025-05-24" に。曜日や「祝・」といった部分は不要なので除去。
数字全般：全角数字が混在していたら半角に統一。Pythonではstr.translateでマッピングテーブルを使うと高速です。
また、文字コードの統一もここで行います。取得文字列がPython内部ではUnicodeになっていますが、念のため想定外の文字（例えばASCII制御文字）が紛れたら除去します。馬名などに特殊記号が入ることはあまりありませんが、「タケユタカ◎」のような◎記号（騎手クラブ注）などもしあれば削る、といった処理も含めます。
コース情報の扱い：レースのコース（芝・ダート、左回り右回り、内外など）の情報はHTML上テキストで載っていますが、自動抽出して標準化するのは難しい場合があります。例えば「芝2000m（右）」や「芝2000m（京都外）」など表記揺れが考えられます。v4ではcourse_idを手動マスタで管理するとしています。対策：コースに関しては、事前に全コースのパターンを把握してマスタを用意し、テキスト→マスタIDにマッピングするプロセスをTransformに組み込むことです。たとえば、正規表現で「東京.*芝.*左」ならTOK_T_LEFTといったIDに対応付ける、といった具合です。完全自動化が難しければ、courseについては解析後にNULLのままにしておき、あとで手動で埋める方法も検討します（モデルに必須でなければ後回し可）。
データ不整合への対処：稀に、公式発表の取り消し等でデータが更新されるケースが考えられます（例えば失格裁定で着順が繰り上がるなど）。スクレイピングのタイミング次第では古い情報を取得してしまう可能性もあります。対策：これは難しい問題ですが、例えば後日再取得や差分チェックの仕組みを導入します。レース結果ページをすぐ取得するだけでなく、数日後にもう一度アクセスしてHTMLを比較し、差異があれば更新するという手順です。そこまで厳密にやるかは運用ポリシー次第ですが、GIなど重要レースだけでも二重チェックすると信頼性が増します。
Transform段階は、コード実装上は地味ですがデータ品質に直結する重要フェーズです。上記の対策を施しつつ、ユニットテストで期待通りパース・変換できているか確認することも大切です。典型的なレース・特殊なレース（出走取り消しあり等）のHTMLをサンプルに、変換結果（Pythonのdictやデータフレーム）が正しいか検証して、問題発生時には都度ロジックを修正していきます。
Load（格納段階）の難所と対策
Load段階では、Transformで得た整形済みデータをデータベースに投入します。ここでの難所はデータベース設計との擦り合わせと、実運用上の堅牢性です。
スキーマとの適合：v4スキーマで定義されたテーブル・カラムに、変換後データがきちんとマップされるか確認が必要です。例えば、raceテーブルとrace_resultsテーブルのリレーション（race_id）が一致しているか、主キー制約に矛盾がないかなどです。対策：ロード処理前に、Transform結果のデータ型・値域がスキーマに適合するか検証します。例えば、race_idはTEXT主キー（12桁）なので、12桁以外の値が混入していないか、NULLになっていないかチェックします。SQLiteを使う場合は厳密な型制約は緩いですが、整合性（FOREIGN KEYなど）は注意深く担保します。v4ではIDは公式由来に統一する方針なので、各IDの桁数・形式も正規表現で検証しておくと良いでしょう。
トランザクション管理：大量のレコードをインポートする際、途中失敗した場合に中途半端な状態が残る恐れがあります。対策：SQLiteであれば、Python側でトランザクション（BEGIN/COMMIT）を適切に貼るか、ある程度バルクでinsertしてまとめてコミットする戦略を取ります。また、UPSERT（INSERT OR REPLACE）を活用し、同一race_idの重複挿入によるエラーを回避します。v4の指針でも、レーステーブルはINSERT OR REPLACEで更新、結果テーブルは主キー（race_id, 枠番, 馬番 等）で一意制約を張りつつINSERTしていく想定です。実装では、SQLiteのメリットである柔軟さを活かし、id重複時は上書き・新規は追加という形にします。これにより、同じレースを誤って二度ロードしてもデータは壊れません（ただし基本はExtract段階で同じレースは二度取得しない前提です）。
リレーションの整備：horses、jockeys、trainersといったマスタ系テーブルにもデータを登録する必要があります。結果ページから各IDと名前は取得できるため、これらも同時にロードします。ただ、同じ人物・馬が複数レースに出るため、重複挿入しない工夫が必要です。対策：マスタテーブルではPRIMARY KEYをidに設定し、INSERT時にCONFLICT(REPLACE or IGNORE)を利用します。例えば、初めて出現するhorse_idならINSERTされ、既に存在するhorse_idなら無視（あるいは名前に差異があれば更新）する、といった方針です。実装上は、bulk insertの前にPython側でsetを用いて重複排除する、またはSQLのINSERT OR IGNOREを使う方法が取れます。
NULL/欠損値の扱い：取得しない項目（前走情報など）はNULLで入れる必要があります。また、レース中止などでタイムが無い場合のタイム、馬体重増減が "---" の場合など、DBにはNULLに相当する値を入れる判断が必要です。対策：Transform段階で、これら特例は予めNone（Python）にしておき、INSERT時にはNULLとして扱わせます。例えばタイムが"--"ならtime=None、増減がNone（型はINT）ならそのままNULL挿入、という具合です。統一して欠損表現することで、後続処理（分析時のNaN処理等）も簡易になります。
性能と拡張性：全レース約数万件のデータを蓄積することを考えると、ロードの性能も無視できません。一件ずつINSERTしてコミットしていたら非常に遅いです。対策：SQLiteでは、一度のトランザクションでまとめてINSERTする方が速いため、できればexecutemanyで複数行インサート、コミットをできるだけまとめるようにします。PythonでレースごとにINSERT文を実行するのではなく、可能なら全レース分のデータをメモリに用意して一括ロードする手もあります。ただしメモリ使用量との兼ね合いがあるので、例えば1開催（数十レース）ずつコミットするといったバランスを取ります。
以上がETL各段階の主な難所とその対策です。要約すると、Extractでは過剰アクセスを避けつつ確実にデータを拾う、Transformではフォーマット揺れや変換ミスを潰す、LoadではDB一貫性と重複処理に留意することが肝要です。それぞれにおいてログを詳細に記録し、何か問題が起きた際に追跡できるようにしておくと、運用段階でのデバッグが容易になります。例えば、どのレースでパースに失敗したか、どのSQLでエラーになったか等をログファイルに残す設計を推奨します。こうした対策によって、完全自動ETLの実現にグッと近づけるでしょう。
8. レース結果データ取得の自動化アプローチ比較と現実的な判断
最後に、レース結果データ収集を完全自動化するアプローチの種類とそれぞれの長所・短所を比較し、本プロジェクトにおける現実的な選択について述べます。考えられるアプローチは大きく以下の3つです。 (A) 完全自動クロール方式 – 人手による事前データ投入なしに、クロールだけで全情報を取得する方法です。具体的には、カレンダーページから全開催日を巡回し、順次リンクを辿って全レース結果ページを取得する全自動クローラーを作成します。スケジュールやrace_idのリストなどもすべてリアルタイムにサイトから取得します。
メリット: 人的管理が不要で、新たなレースも自動検知できます。サイト構造変更にも対応しやすく、常に公式サイトの最新情報をソースとするためデータの出所が一貫しています。過去データもプログラムを回せば一括取得可能です。
デメリット: 実装が複雑になりがちで、実行時間・負荷も大きいです。例えば1970年代の過去レースまで遡るようなケースでは何万件というリンクを踏む必要があります。サーバへの負荷やブロックリスクも高まります。また、全自動で巡回するため制御を誤ると無限ループや重複取得の恐れもあります。開発コストも高めで、しっかりテストしないと信頼性を欠く可能性があります。
整合性・再現性: 同じクロールを再度回せば基本同じデータが得られますが、サイトの更新時期によって取れる内容が変わる（例えば直後と一週間後で制裁情報が追加される等）可能性があります。再現性を高めるには、保存HTMLを参照するなどしてブレを少なくする工夫が必要です。
(B) race_id＋HTML保存型方式 – 予め分かっているrace_idの一覧に基づいて、対応する結果ページのHTMLを取得・保存し、それを解析する方法です。言わば「データ取得」と「サイト内リンク探索」を切り離したアプローチです。race_idはJRAの公式ID体系で決まっているため、例えば過去の開催成績書などから全race_idをリストアップできるなら、それを使って一括取得します。
メリット: 不要な巡回を省けるため効率的です。race_idさえ正しければダイレクトに該当ページのCNAMEを使ったURLにアクセスできる（あるいはCNAMEを導出するルーチンを別途作成する）なら、通信コストは最小になります。また、システム上でrace_idリストを管理することで進捗管理もしやすいです（取得済・未取得の把握など）。開発コストも、クロールロジックを組むよりは低く抑えられます。
デメリット: 根本的に、race_idから直接ページ取得ができない問題（第3章参照）があるため、完全にはこの方法だけで完結しない恐れがあります。実際にはまず一度は(A)方式でCNAMEコードを取得する必要があります。また、新規レースのrace_idをどう取得するかという課題もあります。JRAの開催スケジュールからある程度推測できますが、正確には公式発表資料等を別途パースする必要があります。それを怠ると、新規race_idをシステムが認識できずデータ漏れが起こります。
整合性・再現性: race_idベースで取得する限り、公式のID体系が不変なら再現性は高いです。取得したHTMLを保存する前提なので、後からデータを追加しても一貫性が保てます。ただしCNAMEの更新があれば、再度race_id→CNAMEマッピングを取得し直す必要があります。その意味で、完全に外部知識無しで成り立つわけではありません。
(C) ハイブリッド方式 – 上記(A)と(B)を組み合わせた方法です。基本はrace_id管理で効率よく進めつつ、race_idリスト自体の構築やCNAME取得には限定的にクロールを用いる、という折衷案です。例えば、年間の開催カレンダーと出馬表PDFから全race_idを抽出しておき、初回データ取得時にはそれを元に(B)方式でHTMLを集める。その際、CNAMEが未知なので実際には開催ページをクロールしてCNAMEを得るなど補助的に(A)も使う。新規開催ごとに、開催日ページだけ見に行ってrace_idとCNAMEをひも付けておく、など段取りを工夫します。
メリット: 重要部分は自動化しつつ、煩雑なところはあらかじめ情報を与えることで、安定性と効率のバランスを取れます。たとえばJRAの年間開催計画は事前に公表されていますから、それを元にシステムに「この日に何回開催がある」と教えることができます。完全クロールに比べ無駄が減り、race_idがキーにあることでデータ統合も容易です。CNAMEの規則性変更にも、都度開催ページを見に行くことで対応できます。
デメリット: 設計がやや複雑になり、いくぶん人的メンテナンスも必要です。例えば新年度が始まったら新しい開催マスタを入力する、などの工程が発生しえます。また複数情報源（公式サイト＋事前情報）を使うため、万一不整合があるとバグの原因になります（例：事前リストにあるrace_idが実際には行われなかったなど）。もっとも中央競馬では開催中止以外で計画が大きく変わることは稀なので、実害は少ないでしょう。
整合性・再現性: ハイブリッドでは基準となるrace_idリストを人間が管理できる分、取得漏れや重複が起きにくくなります。再現性も高く、同じリストをなぞれば常に同じ結果を得られます。サイト構造変更への対応も、クロール部分を調整するだけで済むので比較的柔軟です。さらに、HTML保存を組み合わせれば一度取得したものは使い回せます。
以上の比較を踏まえ、現実的な判断として本プロジェクトでは(C)ハイブリッド方式を採用するのが望ましいと考えられます。理由は次のとおりです。
開発効率と安定性：完全クロールは理想的ですが、開発・テストに時間がかかり不確定要素も多いです。一方ハイブリッドなら、手動取得可能な公式情報を活用することで実装を簡素化でき、想定外の事態も減らせます。例えば年次のクラス名称変更（例：500万下→1勝クラスのような変更）があっても、事前に把握してマスタに反映しておけばシステムに組み込めます
note.com
。全てをプログラムで推測させるより確実で、安定稼働につながります。
データ品質の担保：race_idをキーとして明示的に扱うことで、データベース上の一意性や整合性が担保しやすくなります。クロールでリンク辿りのみだと、何をキーに統合するか自明でなく、後処理でrace_idを抽出してキーにすることになります。それなら初めからキーを意識した手法の方がすっきりします。ハイブリッドはその思想に沿っています。
負荷と礼節：ハイブリッド方式では無駄なアクセスを極力省けるため、JRAサーバーへの負荷も軽減されます。例えば年初に全race_idを登録しておけば、開催当日に必要なデータ取得だけをピンポイントで実施できます。完全クロールだと常にサイトを舐め回す形になり、負荷が高いですし、外部から見ると機械的アクセスが目立ちます。適切に間引いたアクセスであれば、公式への迷惑も少なく、長期的に安定して利用できるでしょう。
将来的な拡張：JRA以外のデータ（地方競馬や海外など）を扱う場合、完全クロールだとサイトごとに新規開発が必要ですが、race_idベース管理ならID体系を追加するだけで対応しやすくなります。もっとも地方競馬はJRAとは別サイトですが、考え方としてデータキー中心に収集するアプローチは再利用可能です。
結論として、本プロジェクトではハイブリッド方式で進め、以下のような手順を想定します。
年間開催計画等からrace_idリストや開催情報を取得・設定（手動またはスクリプト補助）。
その情報をもとに、各開催日ページからCNAMEを取得する処理を実行（開催ごとに最低1回のクロール）。
得られたCNAMEマッピングを保存し、各レース結果ページをダイレクトに取得してHTML保存。
Transform＆Loadを行いデータベース構築。
新しいレースが追加開催されるごとに、必要な分だけ1と2を更新・実行する。
このようにすれば、完全自動ではない部分（主に開催計画の投入）は年数回程度で済み、その他の部分はスクリプトで自動化できます。整合性は人間のチェックも介在する分高まり、再現性も保存HTMLにより保証されます。開発コストも無理にCNAME生成ロジックの逆算法を探る必要がなく抑えられますし、安定性もコンスタントに維持できるでしょう。 もちろん、ゆくゆくは完全自動クロールに近づけるのが理想ですが、現時点では上記手法が最も実践的と判断されます。重要なのは、データ取得の確実性と長期運用可能な枠組みです。本白書で分析した通り、JRA公式サイトには特殊な仕掛けがあるものの、それらを正しく理解し対策を講じれば、信頼性の高いデータ収集基盤を構築できる見込みです。その際には常に「公式サイトへの負荷配慮」「構造変化への監視」「データ品質優先」の三点を意識し、システムを設計・改善していくことが肝要でしょう。
ken3memo.hatenablog.com
これにより、安定した競馬データの蓄積と予測モデルへの供給が実現できると考えています。
引用

何でもやってみよう！！: JRAのWEBページをpythonでスクレイピングしてみる（その１）

https://doanythings0.blogspot.com/2019/10/jrawebpython.html

何でもやってみよう！！: [Python]JRAのWEBページをPythonでスクレイピングしてみる（その2）

https://doanythings0.blogspot.com/2020/02/jrawebpython2.html

レース結果2025年5月24日（土曜）2回東京9日 5レース - JRA

https://www.jra.go.jp/JRADB/accessS.html?CNAME=pw01sde1005202502090520250524/A1

XXXXXさんへ JRA レース番号 URLの探り方 CNAME=の法則がわからなくてスミマセン - 三流君 ken3のmemo置き場

https://ken3memo.hatenablog.com/entry/2023/01/22/100000

何でもやってみよう！！: [Python]JRAのWEBページをPythonでスクレイピングしてみる（その2）

https://doanythings0.blogspot.com/2020/02/jrawebpython2.html

何でもやってみよう！！: [Python]JRAのWEBページをPythonでスクレイピングしてみる（その2）

https://doanythings0.blogspot.com/2020/02/jrawebpython2.html

何でもやってみよう！！: [Python]JRAのWEBページをPythonでスクレイピングしてみる（その2）

https://doanythings0.blogspot.com/2020/02/jrawebpython2.html

XXXXXさんへ JRA レース番号 URLの探り方 CNAME=の法則がわからなくてスミマセン - 三流君 ken3のmemo置き場

https://ken3memo.hatenablog.com/entry/2023/01/22/100000

レース結果2025年11月2日（日曜）4回東京11日 11レース - JRA

https://www.jra.go.jp/JRADB/accessS.html?CNAME=pw01sde1005202504111120251102/F7

XXXXXさんへ JRA オッズ取得 ホームページ「onClick=doAction が なんでPOSTだとわかったんですか？」と質問されたので - 三流君 ken3のmemo置き場

https://ken3memo.hatenablog.com/entry/2022/05/08/213000

XXXXXさんへ JRA オッズ取得 ホームページ「onClick=doAction が なんでPOSTだとわかったんですか？」と質問されたので - 三流君 ken3のmemo置き場

https://ken3memo.hatenablog.com/entry/2022/05/08/213000

XXXXXさんへ JRA オッズ取得 ホームページ「onClick=doAction が なんでPOSTだとわかったんですか？」と質問されたので - 三流君 ken3のmemo置き場

https://ken3memo.hatenablog.com/entry/2022/05/08/213000

XXXXXさんへ JRA オッズ取得 ホームページ「onClick=doAction が なんでPOSTだとわかったんですか？」と質問されたので - 三流君 ken3のmemo置き場

https://ken3memo.hatenablog.com/entry/2022/05/08/213000

XXXXXさんへ JRA オッズ取得 ホームページ「onClick=doAction が なんでPOSTだとわかったんですか？」と質問されたので - 三流君 ken3のmemo置き場

https://ken3memo.hatenablog.com/entry/2022/05/08/213000

XXXXXさんへ JRA オッズ取得 ホームページ「onClick=doAction が なんでPOSTだとわかったんですか？」と質問されたので - 三流君 ken3のmemo置き場

https://ken3memo.hatenablog.com/entry/2022/05/08/213000

XXXXXさんへ JRA オッズ取得 ホームページ「onClick=doAction が なんでPOSTだとわかったんですか？」と質問されたので - 三流君 ken3のmemo置き場

https://ken3memo.hatenablog.com/entry/2022/05/08/213000

XXXXXさんへ JRA オッズ取得 ホームページ「onClick=doAction が なんでPOSTだとわかったんですか？」と質問されたので - 三流君 ken3のmemo置き場

https://ken3memo.hatenablog.com/entry/2022/05/08/213000

何でもやってみよう！！: JRAのWEBページをpythonでスクレイピングしてみる（その１）

https://doanythings0.blogspot.com/2019/10/jrawebpython.html

何でもやってみよう！！: JRAのWEBページをpythonでスクレイピングしてみる（その１）

https://doanythings0.blogspot.com/2019/10/jrawebpython.html

何でもやってみよう！！: [Python]JRAのWEBページをPythonでスクレイピングしてみる（その2）

https://doanythings0.blogspot.com/2020/02/jrawebpython2.html

何でもやってみよう！！: [Python]JRAのWEBページをPythonでスクレイピングしてみる（その2）

https://doanythings0.blogspot.com/2020/02/jrawebpython2.html

何でもやってみよう！！: [Python]JRAのWEBページをPythonでスクレイピングしてみる（その2）

https://doanythings0.blogspot.com/2020/02/jrawebpython2.html

何でもやってみよう！！: [Python]JRAのWEBページをPythonでスクレイピングしてみる（その2）

https://doanythings0.blogspot.com/2020/02/jrawebpython2.html

何でもやってみよう！！: JRAのWEBページをpythonでスクレイピングしてみる（その１）

https://doanythings0.blogspot.com/2019/10/jrawebpython.html

〖無料ダウンロード〗JRAオッズ自動更新Excel｜Power Queryで最新オッズを一瞬で取得 | ITツールのある日常

https://jinseimosaku.com/jra_oddsget_excel/

〖無料ダウンロード〗JRAオッズ自動更新Excel｜Power Queryで最新オッズを一瞬で取得 | ITツールのある日常

https://jinseimosaku.com/jra_oddsget_excel/

何でもやってみよう！！: [Python]JRAのWEBページをPythonでスクレイピングしてみる（その2）

https://doanythings0.blogspot.com/2020/02/jrawebpython2.html

何でもやってみよう！！: [Python]JRAのWEBページをPythonでスクレイピングしてみる（その2）

https://doanythings0.blogspot.com/2020/02/jrawebpython2.html

何でもやってみよう！！: [Python]JRAのWEBページをPythonでスクレイピングしてみる（その2）

https://doanythings0.blogspot.com/2020/02/jrawebpython2.html

XXXXXさんへ JRA レース番号 URLの探り方 CNAME=の法則がわからなくてスミマセン - 三流君 ken3のmemo置き場

https://ken3memo.hatenablog.com/entry/2023/01/22/100000

XXXXXさんへ JRA オッズ取得 ホームページ「onClick=doAction が なんでPOSTだとわかったんですか？」と質問されたので - 三流君 ken3のmemo置き場

https://ken3memo.hatenablog.com/entry/2022/05/08/213000

何でもやってみよう！！: [Python]JRAのWEBページをPythonでスクレイピングしてみる（その2）

https://doanythings0.blogspot.com/2020/02/jrawebpython2.html

何でもやってみよう！！: [Python]JRAのWEBページをPythonでスクレイピングしてみる（その2）

https://doanythings0.blogspot.com/2020/02/jrawebpython2.html
data_sources.md

file://file-9Hr8enmfRNHpZkXUdyj9iU
data_sources.md

file://file-9Hr8enmfRNHpZkXUdyj9iU

何でもやってみよう！！: JRAのWEBページをpythonでスクレイピングしてみる（その１）

https://doanythings0.blogspot.com/2019/10/jrawebpython.html

XXXXXさんへ JRA レース番号 URLの探り方 CNAME=の法則がわからなくてスミマセン - 三流君 ken3のmemo置き場

https://ken3memo.hatenablog.com/entry/2023/01/22/100000

XXXXXさんへ JRA レース番号 URLの探り方 CNAME=の法則がわからなくてスミマセン - 三流君 ken3のmemo置き場

https://ken3memo.hatenablog.com/entry/2023/01/22/100000

〖無料ダウンロード〗JRAオッズ自動更新Excel｜Power Queryで最新オッズを一瞬で取得 | ITツールのある日常

https://jinseimosaku.com/jra_oddsget_excel/

何でもやってみよう！！: [Python]JRAのWEBページをPythonでスクレイピングしてみる（その2）

https://doanythings0.blogspot.com/2020/02/jrawebpython2.html

何でもやってみよう！！: [Python]JRAのWEBページをPythonでスクレイピングしてみる（その2）

https://doanythings0.blogspot.com/2020/02/jrawebpython2.html

何でもやってみよう！！: [Python]JRAのWEBページをPythonでスクレイピングしてみる（その2）

https://doanythings0.blogspot.com/2020/02/jrawebpython2.html

レース結果の見方 - JRA

https://www.jra.go.jp/JRADB/mikata/result.html
data_sources.md

file://file-9Hr8enmfRNHpZkXUdyj9iU

2025年11月2日(日曜) 4回東京11日 - レース結果

https://sp.jra.jp/JRADB/accessS.html?CNAME=sw01sde1005202504110120251102/32
data_sources.md

file://file-9Hr8enmfRNHpZkXUdyj9iU

レース結果2025年11月2日（日曜）4回東京11日 11レース - JRA

https://www.jra.go.jp/JRADB/accessS.html?CNAME=pw01sde1005202504111120251102/F7
data_sources.md

file://file-9Hr8enmfRNHpZkXUdyj9iU
data_sources.md

file://file-9Hr8enmfRNHpZkXUdyj9iU

2021年11月28日(日曜) 5回東京8日 - レース結果

https://sp.jra.jp/JRADB/accessS.html?CNAME=sw01sde1005202105081220211128/85
data_sources.md

file://file-9Hr8enmfRNHpZkXUdyj9iU
data_sources.md

file://file-9Hr8enmfRNHpZkXUdyj9iU

JRAレース結果〖CSVファイル作成→MySQLインポート〗①｜hiroly

https://note.com/hiroly2317/n/n63a1754c9251

JRAレース結果〖CSVファイル作成→MySQLインポート〗①｜hiroly

https://note.com/hiroly2317/n/n63a1754c9251
data_sources.md

file://file-9Hr8enmfRNHpZkXUdyj9iU
data_sources.md

file://file-9Hr8enmfRNHpZkXUdyj9iU

2021年11月28日(日曜) 5回東京8日 - レース結果

https://sp.jra.jp/JRADB/accessS.html?CNAME=sw01sde1005202105081220211128/85

レース結果2024年8月10日（土曜）3回新潟1日 8レース - JRA

https://www.jra.go.jp/JRADB/accessS.html?CNAME=pw01sde1004202403010820240810/2B

何でもやってみよう！！: [Python]JRAのWEBページをPythonでスクレイピングしてみる（その2）

https://doanythings0.blogspot.com/2020/02/jrawebpython2.html
table_definitions.md

file://file-KmBiuD938yv2ixKPmkxwXf
data_sources.md

file://file-9Hr8enmfRNHpZkXUdyj9iU
table_definitions.md

file://file-KmBiuD938yv2ixKPmkxwXf
data_sources.md

file://file-9Hr8enmfRNHpZkXUdyj9iU
data_sources.md

file://file-9Hr8enmfRNHpZkXUdyj9iU

何でもやってみよう！！: [Python]JRAのWEBページをPythonでスクレイピングしてみる（その2）

https://doanythings0.blogspot.com/2020/02/jrawebpython2.html
data_sources.md

file://file-9Hr8enmfRNHpZkXUdyj9iU
data_sources.md

file://file-9Hr8enmfRNHpZkXUdyj9iU
data_sources.md

file://file-9Hr8enmfRNHpZkXUdyj9iU
data_sources.md

file://file-9Hr8enmfRNHpZkXUdyj9iU
etl_plan.md

file://file-De5SRhhzkKBWfptzcZUJNX
data_sources.md

file://file-9Hr8enmfRNHpZkXUdyj9iU
etl_plan.md

file://file-De5SRhhzkKBWfptzcZUJNX
etl_plan.md

file://file-De5SRhhzkKBWfptzcZUJNX
etl_plan.md

file://file-De5SRhhzkKBWfptzcZUJNX

JRAレース結果〖CSVファイル作成→MySQLインポート〗①｜hiroly

https://note.com/hiroly2317/n/n63a1754c9251
すべての情報源

doanythi....blogspot

jra.go

ken3memo.hatenablog

jinseimosaku
data_sources.md